# Question-Answering-on-Squad-Dataset---An-encoder-only-Architecture
Designed a Transformer-based question answering model on the SQuAD dataset, employing a transformer encoder architecture with positional encoding, multi-head attention, and layer normalization. Integrated confidence estimation to improve answer reliability and leveraged specialized start and end position heads using deep feedforward networks to enhance prediction accuracy. The model achieved strong performance with a loss of 0.4868, an F1 score of 84%, an EM score of 74%, and consistently maintained answer confidence levels above 70%.
